---
title: "An introduction to AI (...and why you might avoid that term)"
bibliography: "src/references.bib"
categories: [AI/ML, beginner]
execute: 
  echo: false
  freeze: auto
params:
  sl_date: 2025-09-19
  fn: "An introduction to AI (...and why you might avoid that term)"
  id: KA01
format: html
date: "`r params$sl_date`"
---

::: {.content-visible unless-format="revealjs"}

```{r}
#| echo: false
#| results: asis
#| fig-align: left
#| fig-height: 0.6
#| fig-width: 3

source(here::here("R/feed_block.R"))
feed_block(params$id)
#feed_block("An introduction to AI")
source(here::here("R/next_sesh.R"), local = T)
next_sesh("An introduction to AI")
```
:::

::: {.content-visible when-format="revealjs"}

## KIND
The KIND network is an inclusive social learning community for people working with knowledge, information, and data across health, social care, and housing in Scotland.

* [Join our Teams channel](https://forms.office.com/pages/responsepage.aspx?id=veDvEDCgykuAnLXmdF5Jmn79kl25VpJIq3eErXXCYKBUMUpENjBJOENINDRFMUlYQTlCM1RVNzRSRy4u&route=shorturl) for updates, technical support, and events (or see our [FAQ pages](https://nes-dew.github.io/KIND-community-standards/) for more info)
* [Subscribe to our mailing list](https://forms.office.com/pages/responsepage.aspx?id=veDvEDCgykuAnLXmdF5JmpopIZB9ynRJnrPUHVFccipURjM2NkZJUkhGOFlQRjQxRFhVUTgwT0UwVyQlQCN0PWcu) to receive a weekly update about our training and activities
* Visit our [training mini-site](https://nes-dew.github.io/KIND-training/) to find out about our free technical training, including Excel, Power BI, R, and SQL
* Find out more about the [digitally-enabled workforce programme](https://learn.nes.nhs.scot/53965/digitally-enabled-workforce), which operates the KIND network


## Forthcoming sessions
```{r}
KINDR::training_sessions(start_date = params[["sl_date"]], n = 5, hide_area = T)
```

:::: {.notes}
that's mainly technical, but we do some skills training as well. This session is our intro to the tech of AI
::::

:::


## Welcome
+ this session is üå∂: for beginners
+ it aims to do two things:
1. to suggest that the term AI is troublesome
2. to introduce some of the different technologies that get lumped together as AI

## What does AI mean to you?

::: {layout-nrow="1"}
![HAL 9000](src/images/hal.jpg)

![The Terminator](src/images/arnie.jpg)

![Generative AI image of the Pope's coat](src/images/pope.jpg)

![Siri and other personal assistants](src/images/siri.jpg)
:::

::: {.notes}
AI exists in the popular imaginary - independent of the tech itself
:::


## Is AI...
+ Over-hyped?
+ Somewhere in between?
+ Neglected?
+ Other / don't know


## Hype

-   There's a *lot* of hype about AI at the moment (see [this graph](https://www.google.com/imgres?imgurl=https%3A%2F%2Fassets.bwbx.io%2Fimages%2Fusers%2FiqjWHBFdfxIU%2Fi8RUqd2T_1Bs%2Fv2%2FpidjEfPlU1QWZop3vfGKsrX.ke8XuWirGYh1PKgEw44kE%2F-1x-1.png&tbnid=TPmvfqSuBPNC2M&vet=12ahUKEwjw5fuQs4WHAxUkU6QEHZyfDdkQMygDegQIARBP..i&imgrefurl=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2024-06-06%2Fnvidia-microsoft-and-apple-are-bigger-than-china-s-stock-market&docid=beNq4RhizA7SbM&w=1200&h=675&q=nvidia%20microsoft%20graph&ved=2ahUKEwjw5fuQs4WHAxUkU6QEHZyfDdkQMygDegQIARBP), and approx. 100 billion LinkedIn posts)
-   Underneath the hype, there's a lot of genuinely exciting stuff going on too
-   That exciting stuff is likely to have some impact on health and care work

## Why the hype matters

- hype leads to perverse incentives and malfeasance
  - call any rubbish AI, and get paid for it
- that means that understanding what we mean by AI, and what tech calls AI, is important for practitioners
  - there's an industry out there that's profiting from blurring the boundaries
  - getting it wrong might be very important: different tech has different strengths and weaknesses

## A philosophical question
+ do submarines swim?

## Motive

1. The *intelligence* part of AI is as misleading as a swimming submarine
1. There are lots of different technologies that currently fall under the AI umbrella
1. Points 1. and 2. cause blurring of boundaries about what gets called AI
1. That blurring matters in a practical way because of the hot hot hype </br> ![So hot right now screenshot from Zoolander](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRzbu0IXXvTWSW4Bim6PWKkjJQyn6PL7au6LQ&s){height="300px"}



## About this talk

Two linked problems:

+ a worry about intelligence: based on the swimming submarine
+ a worry about diversity: AI is several things, not just one thing


## The Chinese room

@searle1980

> "Suppose that I'm locked in a room and given a large batch of Chinese writing. Suppose furthermore (as is indeed the case) that I know no Chinese, either written or spoken, and that I'm not even confident that I could recognize Chinese writing"

However, he is supplied with a set of intelligible rules for manipulating these Chinese symbols

"ÁÅ´" is the opposite of "Ê∞¥"

"ÂÖ≠" is more than "Âõõ"

## Questions

* Does this poor bloke locked in a room understand the Chinese symbols?
* Now suppose that we start asking him questions (in English):
    * Is "ÂÖ≠" more than "Âõõ"?
    * If so, respond with "ÊòØ". Otherwise respond "‰∏ç"



## Question

-   Is understanding the same thing as being able to produce output in response to input?
- @searle1980 - this is the difference between strong and weak AI


## Back to nice safe words

-   we usually don't worry too much about what words like intelligence, understanding, etc really mean
-   for most purposes, understanding something, and doing that thing, pretty well overlap
-   AI, unfortunately, is an exception
-   big difference between producing output and understanding here

## Why does this matter?

-   Because the current conversation around AI does violence to our usual understanding of basic terms (like intelligence)
    -   We need to do a bit of re-interpreting...
    -   ...particularly because AI can do the input-output part *really* well
-   (side effect) The Chinese Room is an excellent way of understanding what's going on inside some of the current tech

## The tech

-   AI = big umbrella term
-   More specific terms:
    -   *Algorithms* = rule-based ways of producing sensible output
    -   *Expert systems* = more sophisticated expertise-based production of output
    -   *Machine learning* = umbrella term for non-expertise-based production of output
    -   *Large Language Models* = a massively-succesful sub-species of machine learning

## So what's an algorithm?

::: columns
::: {.column width="25%"}
![](src/images/altair.jpg) [(Packard 1979)](https://www.goodreads.com/book/show/191062.The_Third_Planet_from_Altair)
:::

::: {.column width="60%"}
-   Algorithm = rule (roughly)
    -   if something happens, do something
-   made from expert input and evidence
:::
:::

## An example algorithm

![](src/images/nice_136.png){fig-align="center"}

## Related expertise-based tools

"See also..." references in indexes, library catalogues, wikipedia

![Wikipedia cue sports](src/images/cue.png)

-   [Brilliant 1996 Master's dissertation](https://files.eric.ed.gov/fulltext/ED401916.pdf) looking at the state of "see also..." referencing in Ohio's public libraries

## How about something more complicated?


::: columns
:::: {.column width="35%"}

![Part of the MYCIN inference system](src/images/monitor.png)
::::

:::: {.column width="60%"}
- one problem with algorithms: how to handle conflicting information?
-   An expert system - [MYCIN](https://en.wikipedia.org/wiki/Mycin) [@shortliffe1975]
    -   designed to identify bacterial infections and suitable Rx
    -   600 rules, supplied by experts
    -   asks users a series of clinical questions
    -   combines the answers using a (fairly simple) inference system
    -   able to manage some conflicting information - unlike simpler algorithms

::::

:::

## Machine learning

-   A next step: can we provide learning rules to a system, and let it figure out the details for itself?

![https://commons.wikimedia.org/wiki/File:Supervised_machine_learning_in_a_nutshell.svg](src/images/sml.png)

## This is supervised learning

-   supervision = labelled observations used for training and testing
-   Lots of health examples with promising results:
    -   diabetic retinopathy [@mookiah2013]
    -   ECG [@aziz2021]
    -   fractures, melanoma, ...

:::: {.content-visible unless-format="revealjs"}

## There's a lot going on in that Machine learner box

+ e.g. artificial neural networks (ANNs)
+ ANNs can can potentially replicate *any* input-output transformation (learn anything, in other words)
+ that capacity depends on complexity: simple units in complex arrangements
+ we can't draw simple conclusions about likely behaviour from this structure

::: {#fig-neuro layout-ncol=2}
![[wikimedia](https://commons.wikimedia.org/wiki/Category:Camillo_Golgi#/media/File:Camillo_Golgi's_image_of_a_dog%E2%80%99s_olfactory_bulb\_(detail_2).jpg)](../src/images/clipboard-2953597145.png)
![Example of hidden layers](../src/images/net4.png)
:::

::::

:::: {.content-visible when-format="revealjs"}

## There's a lot going on in that Machine learner box

+ e.g. artificial neural networks (ANNs)
+ ANNs can can potentially replicate *any* input-output transformation (learn anything, in other words)
+ that capacity depends on complexity: simple units in complex arrangements
+ we can't draw simple conclusions about likely behaviour from this structure

## There's a lot going on in that Machine learner box
![[wikimedia](https://commons.wikimedia.org/wiki/Category:Camillo_Golgi#/media/File:Camillo_Golgi's_image_of_a_dog%E2%80%99s_olfactory_bulb\_(detail_2).jpg)](../src/images/clipboard-2953597145.png)

## There's a lot going on in that Machine learner box
![Example of hidden layers](../src/images/net4.png)

::::


## Fashion MNIST


![[Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)](src/images/mnist.png)
+ an example of a labelled dataset

## Labelling is hard

Producing labelled datasets is hard:

-   generally must be very large
-   generally requires expert classification
-   must be done with great accuracy
    -   scale bar problem [@winkler2021]
-   so dataset labelling is wildly expensive and thankless
    -   Is there a way of doing something similar without spending trillions classifying everything in the world by hand?


## Unsupervised learning

![English-languge autocomplete suggestions](src/images/google.png){fig-align="center"}

## Unsupervised learning

![Autocomplete sources](src/images/explain.png){fig-align="center"}

## Unsupervised learning

![German-languge autocomplete suggestions](src/images/go√∂gle.png){fig-align="center"}

## Unsupervised learning

-   No-one is writing a list of possible searches starting with "Large..."
-   Nor are they classifying searches into likely/unlikely, then training a model
-   Instead, the model is looking at data (searches, language, location, trends) and calculating probabilities
    -   [2011 blog post](https://googleblog.blogspot.com/2011/04/more-predictions-in-autocomplete.html)
    -   [2020 PR piece](https://blog.google/products/search/how-google-autocomplete-predictions-work/)
    -   [2020 build your own in JS](https://medium.com/analytics-vidhya/build-a-simple-autocomplete-model-with-your-own-google-search-history-ead26b3b6bd4)
    
## Deep learning?

-   The terminology gets confusing again at this point:
    -   some describe this as *deep learning*
    -   better to call this a *language model*

## Transformers

![Transformer model architecture](src/images/transformer.png)


## Large language models

What if we were more ambitious with the scope of our language model?

-   Find masses of language data
    -   chatGPT uses basically the whole web before September 2021
-   Build a model capable of finding patterns in that data
    -   Attention model used in chatGPT [@vaswani2017]
-   Allow the model to calculate probabilities based on those patterns
    -   lots of work going on at present allowing models to improve in response to feedback etc

## Large language models

-   superb at generating appropriate text, code, images, music...
-   but production vs understanding
    -   e.g. hallucinations, phantom functions...
-   training is extremely computationally expensive
    -   questions about inequality and regulatory moating
        -   no-one but FAANG-sized companies can afford to do this
    - training is also surprisingly manual

## Ethics

- your web content, my model, my paycheque
- where's the consent here?
- big serious worries about bias in some kinds of output
- rights violations via AI
- no settled questions around responsibility
- UK GDPR etc assume data is identifiable. That's not true in LLMs.

## Punchline

-   On balance, while there's hype here, there's also lots of substance and interest
-   LLMs have become *much* better at producing plausible output, across a *greatly* expanded area
-   A strength: fantastic ways to speed-up experts
-   A danger: LLMs excel at producing truth-like output
-   But big serious legal and ethical trouble ahead - we're not good at dealing with distributed responsibility

## Thumbs-up for specificity
+ many of the touted benefits are technology-specific
    + e.g. if we want to understand why decisions are getting made in a particular way, an expert system is better than a LLM
+ we should probably start asking "what do you mean by AI" whenever we're trying to make decisions about it

## Conclusion

1. The *intelligence* part of AI is as misleading as a swimming submarine
1. There are lots of different technologies that currently fall under the AI umbrella
1. Points 1. and 2. cause blurring of boundaries about what gets called AI
1. That blurring matters in a practical way for us in health and care


::: {.content-visible when-format="revealjs"}
## Forthcoming sessions
```{r}
KINDR::training_sessions(start_date = params[["sl_date"]], n = 5, hide_area = T)
```

## Feedback

Please can you [spare us one minute of your time to give feedback](`r KINDR::feedback_url("An introduction to AI", date = params[["sl_date"]]) `)?
:::


## References

