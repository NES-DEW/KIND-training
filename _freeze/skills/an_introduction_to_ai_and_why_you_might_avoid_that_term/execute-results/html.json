{
  "hash": "c307868962251bd53f3acc7fd772f2b2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"An introduction to AI (...and why you might avoid that term)\"\ndate: 2025-03-04\nbibliography: \"src/references.bib\"\nexecute: \n  freeze: auto\ncategories: [AI/ML, beginner]\n---\n\n::: {.cell layout-align=\"left\"}\n  \n## Previous attendees have said...  \n  \n- 18 previous attendees have left feedback\n- 100% would recommend this session to a colleague\n- 100% said that this session was pitched correctly  \n\n  \n![](an_introduction_to_ai_and_why_you_might_avoid_that_term_files/figure-html/unnamed-chunk-1-1.png){fig-align='left' width=288}  \n  \n:::{.callout-note}  \n### Three random comments from previous attendees  \n- Great overview, fascinating discussion - I really enjoy all of the references to explore at KIND sessions\n- Chatty, fun, informative\n- Thought it was a good intro but would be interesting to look at the main differences between \"old AI\" and new generative AI, The session you did looking at expert systems was good - are these classed as AI? When I was younger they were but now seems to refer mainly to generative AI so interesting to look at some of the history/hype vs the reality and the fact that most of the new AI is black box, so you can't trace the algorithm back to why it made a particular descision in the way that you could in an expert system. This makes reviewing the Ai's decisions a much harder task..\n  \n:::  \n:::\n\n\n\n\n\n:::{.callout-note collapse=false appearance='default' icon=true}\n## Session materials\n+ [all materials {{< iconify ph:file-zip size=2x >}}](src/ai_intro.zip)\n+ slides [{{< iconify ph:file-html size=2x >}} html](src/ai_intro.html) / [{{< iconify ph:file-pdf size=2x >}} pdf](src/ai_intro.pdf)\n:::\n\n## Welcome\n+ this session is üå∂: for beginners\n+ it aims to do two things:\n1. to suggest that the term AI is troublesome\n2. to introduce some of the different technologies that get lumped together as AI\n\n## A philosophical question\n+ do submarines swim?\n\n## Hype\n\n-   There's a *lot* of hype about AI at the moment (see [this graph](https://www.google.com/imgres?imgurl=https%3A%2F%2Fassets.bwbx.io%2Fimages%2Fusers%2FiqjWHBFdfxIU%2Fi8RUqd2T_1Bs%2Fv2%2FpidjEfPlU1QWZop3vfGKsrX.ke8XuWirGYh1PKgEw44kE%2F-1x-1.png&tbnid=TPmvfqSuBPNC2M&vet=12ahUKEwjw5fuQs4WHAxUkU6QEHZyfDdkQMygDegQIARBP..i&imgrefurl=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2024-06-06%2Fnvidia-microsoft-and-apple-are-bigger-than-china-s-stock-market&docid=beNq4RhizA7SbM&w=1200&h=675&q=nvidia%20microsoft%20graph&ved=2ahUKEwjw5fuQs4WHAxUkU6QEHZyfDdkQMygDegQIARBP))\n-   Underneath the hype, there's a lot of genuinely exciting stuff going on too\n-   That exciting stuff is likely to have some impact on health and care work\n\n## Motive\n\n1. The *intelligence* part of AI is as misleading as a swimming submarine\n1. There are lots of different technologies that currently fall under the AI umbrella\n1. Points 1. and 2. matter in a practical way because of the hype </br> ![So hot right now screenshot from Zoolander](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRzbu0IXXvTWSW4Bim6PWKkjJQyn6PL7au6LQ&s){height=\"300px\"}\n\n## What does AI mean to you?\n\n::: {layout-nrow=\"1\"}\n![HAL 9000](src/images/hal.jpg){width=\"400\" height=\"400\"}\n\n![The Terminator](src/images/arnie.jpg){width=\"400\" height=\"400\"}\n\n![Generative AI image of the Pope's coat](src/images/pope.jpg){width=\"400\" height=\"400\"}\n\n![Siri and other personal assistants](src/images/siri.jpg){width=\"400\" height=\"400\"}\n:::\n\n## Is AI...\n+ Over-hyped?\n+ Somewhere in between?\n+ Neglected?\n+ Other / don't know\n\n## About this talk\n\nTwo linked problems:\n\n+ a worry about intelligence: based on the swimming submarine\n+ a worry about diversity: AI is several things, not just one thing\n\n\n## The Chinese room\n\n@searle1980\n\n> \"Suppose that I'm locked in a room and given a large batch of Chinese writing. Suppose furthermore (as is indeed the case) that I know no Chinese, either written or spoken, and that I'm not even confident that I could recognize Chinese writing\"\n\nHowever, he is supplied with a set of intelligible rules for manipulating these Chinese symbols\n\n\"ÁÅ´\" is the opposite of \"Ê∞¥\"\n\n\"ÂÖ≠\" is more than \"Âõõ\"\n\n## Question\n\nDoes this poor bloke locked in a room understand the Chinese symbols?\n\nNow suppose that we start asking him questions (in English):\n\nIs \"ÂÖ≠\" more than \"Âõõ\"?\n\nIf so, respond with \"ÊòØ\". Otherwise respond \"‰∏ç\"\n\n\n\n## Question\n\n-   Is understanding the same thing as being able to produce output in response to input?\n- @searle1980 - this is the difference between strong and weak AI\n\n\n## Back to nice safe words\n\n-   we usually don't worry too much about what words like intelligence, understanding, etc really mean\n-   for most purposes, understanding something, and doing that thing, pretty well overlap\n-   AI, unfortunately, is an exception\n-   big difference between producing output and understanding here\n\n## Why does this matter?\n\n-   Because the current conversation around AI does violence to our usual understanding of basic terms (like intelligence)\n    -   We need to do a bit of re-interpreting...\n    -   ...particularly because AI can do the input-output part *really* well\n-   (side effect) The Chinese Room is an excellent way of understanding what's going on inside some of the current tech\n\n## The tech\n\n-   AI = big umbrella term\n-   More specific terms:\n    -   *Algorithms* = rule-based ways of producing sensible output\n    -   *Expert systems* = more sophisticated expertise-based production of output\n    -   *Machine learning* = umbrella term for non-expertise-based production of output\n    -   *Large Language Models* = a massively-succesful sub-species of machine learning\n\n## So what's an algorithm?\n\n::: columns\n::: {.column width=\"25%\"}\n![](src/images/altair.jpg) [(Packard 1979)](https://www.goodreads.com/book/show/191062.The_Third_Planet_from_Altair)\n:::\n\n::: {.column width=\"60%\"}\n-   Algorithm = rule (roughly)\n    -   if something happens, do something\n-   made from expert input and evidence\n:::\n:::\n\n## An example algorithm\n\n![](src/images/nice_136.png){fig-align=\"center\"}\n\n## Related expertise-based tools\n\n\"See also...\" references in indexes, library catalogues, wikipedia\n\n![Wikipedia cue sports](src/images/cue.png) . . .\n\n-   [Brilliant 1996 Master's dissertation](https://files.eric.ed.gov/fulltext/ED401916.pdf) looking at the state of \"see also...\" referencing in Ohio's public libraries\n\n## How about something more complicated?\n\n\n::: columns\n:::: {.column width=\"35%\"}\n\n![Part of the MYCIN inference system](src/images/monitor.png)\n::::\n\n:::: {.column width=\"60%\"}\n- one problem with algorithms: how to handle conflicting information?\n-   An expert system - [MYCIN](https://en.wikipedia.org/wiki/Mycin) [@shortliffe1975]\n    -   designed to identify bacterial infections and suitable Rx\n    -   600 rules, supplied by experts\n    -   asks users a series of clinical questions\n    -   combines the answers using a (fairly simple) inference system\n    -   able to manage some conflicting information - unlike simpler algorithms\n\n::::\n\n:::\n\n## Machine learning\n\n-   A next step: can we provide learning rules to a system, and let it figure out the details for itself?\n\n![https://commons.wikimedia.org/wiki/File:Supervised_machine_learning_in_a_nutshell.svg](src/images/sml.png)\n\n## This is supervised learning\n\n-   supervision = labelled observations used for training and testing\n-   Lots of health examples with promising results:\n    -   diabetic retinopathy [@mookiah2013]\n    -   ECG [@aziz2021]\n    -   fractures, melanoma, ...\n\n## A dataset downside\n\n::: columns\n::: {.column width=\"40%\"}\n![[Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)](src/images/mnist.png)\n:::\n\n::: {.column width=\"50%\"}\nProducing labelled datasets is hard:\n\n-   generally must be very large\n-   generally requires expert classification\n-   must be done with great accuracy\n    -   scale bar problem [@winkler2021]\n-   so dataset labelling is wildly expensive and thankless\n    -   Is there a way of doing something similar without spending trillions classifying everything in the world by hand?\n:::\n:::\n\n## Unsupervised learning\n\n![English-languge autocomplete suggestions](src/images/google.png){fig-align=\"center\"}\n\n## Unsupervised learning\n\n![Autocomplete sources](src/images/explain.png){fig-align=\"center\"}\n\n## Unsupervised learning\n\n![German-languge autocomplete suggestions](src/images/go√∂gle.png){fig-align=\"center\"}\n\n## Unsupervised learning\n\n-   No-one is writing a list of possible searches starting with \"Large...\"\n-   Nor are they classifying searches into likely/unlikely, then training a model\n-   Instead, the model is looking at data (searches, language, location, trends) and calculating probabilities\n    -   [2011 blog post](https://googleblog.blogspot.com/2011/04/more-predictions-in-autocomplete.html)\n    -   [2020 PR piece](https://blog.google/products/search/how-google-autocomplete-predictions-work/)\n    -   [2020 build your own in JS](https://medium.com/analytics-vidhya/build-a-simple-autocomplete-model-with-your-own-google-search-history-ead26b3b6bd4)\n-   The terminology gets confusing again at this point:\n    -   some describe this as *deep learning*\n    -   better to call this a *language model*\n\n## Large language models\n\nWhat if we were more ambitious with the scope of our language model?\n\n::: columns\n::: {.column width=\"30%\"}\n![Transformer model architecture](src/images/transformer.png)\n:::\n\n::: {.column width=\"60%\"}\n-   Find masses of language data\n    -   chatGPT uses basically the whole web before September 2021\n-   Build a model capable of finding patterns in that data\n    -   Attention model used in chatGPT [@vaswani2017]\n-   Allow the model to calculate probabilities based on those patterns\n    -   lots of work going on at present allowing models to improve in response to feedback etc\n:::\n:::\n\n## Large language models\n\n-   superb at generating appropriate text, code, images, music...\n-   but production vs understanding\n    -   e.g. hallucinations, phantom functions...\n-   training is extremely computationally expensive\n    -   questions about inequality and regulatory moating\n        -   no-one but FAANG-sized companies can afford to do this\n    - training is also surprisingly manual\n\n## Ethics\n\n- your web content, my model, my paycheque\n- where's the consent here?\n- big serious worries about bias in some kinds of output\n- rights violations via AI\n- no settled questions around responsibility\n- UK GDPR etc assume data is identifiable. That's not true in LLMs.\n\n## Punchline\n\n-   On balance, while there's hype here, there's also lots of substance and interest\n-   LLMs have become *much* better at producing plausible output, across a *greatly* expanded area\n-   A strength: fantastic ways for those with expertise to work faster\n-   A danger: LLMs are great at producing truth-like output. Good enough so that some will be tempted to use them to extend their apparent expertise...\n-   But big serious legal and ethical trouble ahead - we're not good at dealing with distributed responsibility\n\n## Thumbs-up for specificity\n+ many of the touted benefits are technology-specific\n    + e.g. if we want to understand why decisions are getting made in a particular way, an expert system is better than a LLM\n+ we should probably start asking \"what do you mean by AI\" whenever we're trying to make decisions about it\n\n## Conclusion\n\n1. The *intelligence* part of AI is as misleading as a swimming submarine\n1. There are lots of different technologies that currently fall under the AI umbrella\n1. points 1. and 2. really matter because of the hype\n\n## Why the hype matters\n\n- hype leads to perverse incentives and malfescience: call any rubbish AI, and get paid for it\n- that means that both what we mean by AI, and what tech gets included, is extra-important at present - there's an industry out there that's profiting from blurring the boundaries\n\n\n",
    "supporting": [
      "an_introduction_to_ai_and_why_you_might_avoid_that_term_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}